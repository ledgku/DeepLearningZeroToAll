{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab04_Multi_Variable_Linear_Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "orPEPKpWF029",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        },
        "outputId": "f5d16e11-f03e-45e7-a982-0e4daaa963c3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "  \n",
        "x1_data = [73., 93., 89., 96., 73.]\n",
        "x2_data = [80., 88., 91., 98., 66.]\n",
        "x3_data = [75., 93., 90., 100., 70.]\n",
        "y_data = [152., 185., 180., 196., 142.]\n",
        "\n",
        "# placeholders for a tensor that will be always fed\n",
        "x1 = tf.placeholder(tf.float32)\n",
        "x2 = tf.placeholder(tf.float32)\n",
        "x3 = tf.placeholder(tf.float32)\n",
        "\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
        "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
        "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = (x1 * w1) + (x2 * w2) + (x3 * w3) + b\n",
        "\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize. Need a very small learning rate for this data set\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
        "  \n",
        "  if step % 100 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Cost:  52848.914 \n",
            "Prediction:\n",
            " [-58.43853  -56.70121  -63.03264  -65.532646 -42.598267]\n",
            "100 Cost:  12.249643 \n",
            "Prediction:\n",
            " [145.64343 188.35306 178.54744 197.52014 144.27563]\n",
            "200 Cost:  11.728942 \n",
            "Prediction:\n",
            " [145.76613 188.2697  178.58598 197.54063 144.17247]\n",
            "300 Cost:  11.235187 \n",
            "Prediction:\n",
            " [145.88562 188.18854 178.62354 197.56046 144.07216]\n",
            "400 Cost:  10.76691 \n",
            "Prediction:\n",
            " [146.00198 188.10948 178.66014 197.57959 143.97462]\n",
            "500 Cost:  10.322756 \n",
            "Prediction:\n",
            " [146.11536 188.03253 178.69582 197.59808 143.87982]\n",
            "600 Cost:  9.901484 \n",
            "Prediction:\n",
            " [146.22575 187.95758 178.73059 197.61592 143.78763]\n",
            "700 Cost:  9.501909 \n",
            "Prediction:\n",
            " [146.33328 187.88461 178.76447 197.63312 143.69801]\n",
            "800 Cost:  9.122858 \n",
            "Prediction:\n",
            " [146.438   187.8135  178.79749 197.64973 143.6109 ]\n",
            "900 Cost:  8.76325 \n",
            "Prediction:\n",
            " [146.54004 187.74432 178.82968 197.66577 143.52621]\n",
            "1000 Cost:  8.422106 \n",
            "Prediction:\n",
            " [146.6394  187.67694 178.86107 197.68124 143.44388]\n",
            "1100 Cost:  8.098387 \n",
            "Prediction:\n",
            " [146.7362  187.61131 178.89166 197.69614 143.36388]\n",
            "1200 Cost:  7.791224 \n",
            "Prediction:\n",
            " [146.83049 187.5474  178.92148 197.71051 143.28609]\n",
            "1300 Cost:  7.4997168 \n",
            "Prediction:\n",
            " [146.92236 187.48518 178.95056 197.72437 143.2105 ]\n",
            "1400 Cost:  7.2230935 \n",
            "Prediction:\n",
            " [147.01181 187.42456 178.97888 197.73767 143.137  ]\n",
            "1500 Cost:  6.9604745 \n",
            "Prediction:\n",
            " [147.09898 187.36552 179.00652 197.7505  143.06557]\n",
            "1600 Cost:  6.711198 \n",
            "Prediction:\n",
            " [147.18391 187.30804 179.03346 197.76286 142.99617]\n",
            "1700 Cost:  6.474594 \n",
            "Prediction:\n",
            " [147.26662 187.25206 179.05971 197.77472 142.92871]\n",
            "1800 Cost:  6.2498827 \n",
            "Prediction:\n",
            " [147.34721 187.19751 179.08531 197.78613 142.86314]\n",
            "1900 Cost:  6.036569 \n",
            "Prediction:\n",
            " [147.42572 187.14441 179.11029 197.79712 142.79944]\n",
            "2000 Cost:  5.8339415 \n",
            "Prediction:\n",
            " [147.50221 187.09267 179.13461 197.80763 142.73752]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BLGI2qXmMs9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2516
        },
        "outputId": "e5603992-175c-4091-d603-4ffedd593d35"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "  \n",
        "x_data = [[73., 80., 75.], [93., 88., 93.], [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]]\n",
        "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
        "\n",
        "# placeholders for a tensor that will be always feed\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight1')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize. Need a very small learning rate for this data set\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
        "  \n",
        "  if step % 100 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Cost:  4557.259 \n",
            "Prediction:\n",
            " [[204.87263]\n",
            " [260.82486]\n",
            " [249.47061]\n",
            " [272.2767 ]\n",
            " [201.97554]]\n",
            "100 Cost:  17.57047 \n",
            "Prediction:\n",
            " [[145.2599 ]\n",
            " [188.8639 ]\n",
            " [178.7281 ]\n",
            " [195.21992]\n",
            " [147.02667]]\n",
            "200 Cost:  16.657516 \n",
            "Prediction:\n",
            " [[145.42032]\n",
            " [188.75409]\n",
            " [178.77742]\n",
            " [195.25418]\n",
            " [146.88377]]\n",
            "300 Cost:  15.79276 \n",
            "Prediction:\n",
            " [[145.57645]\n",
            " [188.6472 ]\n",
            " [178.82544]\n",
            " [195.28746]\n",
            " [146.74472]]\n",
            "400 Cost:  14.973523 \n",
            "Prediction:\n",
            " [[145.72844]\n",
            " [188.54317]\n",
            " [178.87221]\n",
            " [195.31987]\n",
            " [146.6094 ]]\n",
            "500 Cost:  14.197545 \n",
            "Prediction:\n",
            " [[145.87636]\n",
            " [188.4419 ]\n",
            " [178.91771]\n",
            " [195.35135]\n",
            " [146.47772]]\n",
            "600 Cost:  13.462463 \n",
            "Prediction:\n",
            " [[146.02036]\n",
            " [188.34332]\n",
            " [178.962  ]\n",
            " [195.38197]\n",
            " [146.3496 ]]\n",
            "700 Cost:  12.766157 \n",
            "Prediction:\n",
            " [[146.1605 ]\n",
            " [188.24739]\n",
            " [179.00514]\n",
            " [195.41174]\n",
            " [146.2249 ]]\n",
            "800 Cost:  12.10655 \n",
            "Prediction:\n",
            " [[146.29692]\n",
            " [188.154  ]\n",
            " [179.04712]\n",
            " [195.4407 ]\n",
            " [146.10355]]\n",
            "900 Cost:  11.481684 \n",
            "Prediction:\n",
            " [[146.42973]\n",
            " [188.06311]\n",
            " [179.08798]\n",
            " [195.46884]\n",
            " [145.98547]]\n",
            "1000 Cost:  10.889776 \n",
            "Prediction:\n",
            " [[146.55899]\n",
            " [187.97464]\n",
            " [179.12778]\n",
            " [195.4962 ]\n",
            " [145.87056]]\n",
            "1100 Cost:  10.329109 \n",
            "Prediction:\n",
            " [[146.68481]\n",
            " [187.88852]\n",
            " [179.1665 ]\n",
            " [195.52281]\n",
            " [145.75877]]\n",
            "1200 Cost:  9.797996 \n",
            "Prediction:\n",
            " [[146.80728]\n",
            " [187.80472]\n",
            " [179.20421]\n",
            " [195.54868]\n",
            " [145.64996]]\n",
            "1300 Cost:  9.294817 \n",
            "Prediction:\n",
            " [[146.92651]\n",
            " [187.72311]\n",
            " [179.24092]\n",
            " [195.5738 ]\n",
            " [145.5441 ]]\n",
            "1400 Cost:  8.818239 \n",
            "Prediction:\n",
            " [[147.04254]\n",
            " [187.6437 ]\n",
            " [179.27664]\n",
            " [195.59825]\n",
            " [145.44107]]\n",
            "1500 Cost:  8.366736 \n",
            "Prediction:\n",
            " [[147.15552]\n",
            " [187.56642]\n",
            " [179.31145]\n",
            " [195.62202]\n",
            " [145.34084]]\n",
            "1600 Cost:  7.939048 \n",
            "Prediction:\n",
            " [[147.26546]\n",
            " [187.49118]\n",
            " [179.3453 ]\n",
            " [195.64513]\n",
            " [145.24327]]\n",
            "1700 Cost:  7.533885 \n",
            "Prediction:\n",
            " [[147.3725 ]\n",
            " [187.41794]\n",
            " [179.37828]\n",
            " [195.66757]\n",
            " [145.14836]]\n",
            "1800 Cost:  7.1500907 \n",
            "Prediction:\n",
            " [[147.47668]\n",
            " [187.34666]\n",
            " [179.41039]\n",
            " [195.68942]\n",
            " [145.056  ]]\n",
            "1900 Cost:  6.7865624 \n",
            "Prediction:\n",
            " [[147.57808]\n",
            " [187.27728]\n",
            " [179.44164]\n",
            " [195.71062]\n",
            " [144.96613]]\n",
            "2000 Cost:  6.4421477 \n",
            "Prediction:\n",
            " [[147.6768 ]\n",
            " [187.20975]\n",
            " [179.47206]\n",
            " [195.73125]\n",
            " [144.87868]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FvI7JTfQoU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "651829a0-f639-4ec0-f79a-fc6895aea22a"
      },
      "cell_type": "code",
      "source": [
        "# Loading data from file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "xy = np.loadtxt('/content/gdrive/My Drive/dataset/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "# Make sure the shape and data are OK\n",
        "print(x_data.shape, x_data, len(x_data))\n",
        "print(y_data.shape, y_data)\n",
        "\n",
        "# placeholders for a tensor that will be always feed\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight1')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize. Need a very small learning rate for this data set\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
        "  \n",
        "  if step % 1000 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
        "    \n",
        "# Ask my score\n",
        "print(\"Your score will be \", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
        "print(\"Ohter scores will be \", sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "(6, 3) [[ 73.  80.  75.]\n",
            " [ 93.  88.  93.]\n",
            " [ 89.  91.  90.]\n",
            " [ 96.  98. 100.]\n",
            " [ 73.  66.  70.]\n",
            " [ 53.  46.  55.]] 6\n",
            "(6, 1) [[152.]\n",
            " [185.]\n",
            " [180.]\n",
            " [196.]\n",
            " [142.]\n",
            " [101.]]\n",
            "0 Cost:  146837.48 \n",
            "Prediction:\n",
            " [[-206.78519]\n",
            " [-249.16643]\n",
            " [-245.10269]\n",
            " [-266.62582]\n",
            " [-190.67657]\n",
            " [-140.6381 ]]\n",
            "1000 Cost:  2.4061358 \n",
            "Prediction:\n",
            " [[152.60498]\n",
            " [183.41908]\n",
            " [180.80992]\n",
            " [197.17029]\n",
            " [139.44266]\n",
            " [102.73377]]\n",
            "2000 Cost:  2.1556847 \n",
            "Prediction:\n",
            " [[152.40303 ]\n",
            " [183.53706 ]\n",
            " [180.74397 ]\n",
            " [197.0543  ]\n",
            " [139.65857 ]\n",
            " [102.866585]]\n",
            "Your score will be  [[182.09775]]\n",
            "Ohter scores will be  [[162.7875 ]\n",
            " [180.03133]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lCBUC6s7X06M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2224
        },
        "outputId": "e81cb910-0dcc-4f3b-ca73-9ea6ac7f06e2"
      },
      "cell_type": "code",
      "source": [
        "# Loading data from file\n",
        "# Using tensorflow queue runners \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "filename_queue = tf.train.string_input_producer(['/content/gdrive/My Drive/dataset/data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
        "\n",
        "reader = tf.TextLineReader()\n",
        "key, value = reader.read(filename_queue)\n",
        "\n",
        "# Default values, in case of empty columns. Also specifies the type of the decoded result.\n",
        "record_defaults = [[0.], [0.], [0.], [0.]]\n",
        "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
        "\n",
        "# collect batches of csv in\n",
        "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
        "\n",
        "# placeholders for a tensor that will be always feed\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight1')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize. Need a very small learning rate for this data set\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Start populating the filename queue\n",
        "coord = tf.train.Coordinator()\n",
        "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "for step in range(2001):\n",
        "  x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
        "#   cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
        "#   if step % 10 == 0:\n",
        "#       print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
        "\n",
        "# # Minimize\n",
        "# coord.request_stop()\n",
        "# coord.join(threads)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Expect 4 fields but have 1 in record 0\n",
            "\t [[{{node DecodeCSV_7}}]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OutOfRangeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_694_batch_20/fifo_queue' is closed and has insufficient elements (requested 9, current size 0)\n\t [[{{node batch_20}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-de6ea57c22e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;31m#   cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#   if step % 10 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_694_batch_20/fifo_queue' is closed and has insufficient elements (requested 9, current size 0)\n\t [[node batch_20 (defined at <ipython-input-72-de6ea57c22e8>:17) ]]\n\nCaused by op 'batch_20', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-de6ea57c22e8>\", line 17, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 1019, in batch\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3645, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_694_batch_20/fifo_queue' is closed and has insufficient elements (requested 9, current size 0)\n\t [[node batch_20 (defined at <ipython-input-72-de6ea57c22e8>:17) ]]\n"
          ]
        }
      ]
    }
  ]
}